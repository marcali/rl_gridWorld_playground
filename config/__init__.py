"""Configuration package for RL agents and training"""

from .base_config import *
from .dqn_config import *
from .qlearning_config import *
from .trainer_config import *

__all__ = [
    # Base config
    "GRID_SIZE",
    "MAX_STEPS_PER_EPISODE",
    "START_STATE",
    "GOAL_STATE",
    "N_STATIC_OBSTACLES",
    "N_RANDOM_OBSTACLES",
    "REWARD_GOAL",
    "REWARD_STEP",
    "REWARD_COLLISION",
    "N_EVAL_EPISODES",
    "EVAL_EPSILON",
    "MAX_EVAL_STEPS",
    "FIGURE_SIZE",
    "PATH_FIGURE_SIZE",
    "DPI",
    "N_STATES",
    "N_ACTIONS",
    # DQN config
    "HIDDEN_SIZE",
    "NUM_LAYERS",
    "LEARNING_RATE",
    "MEMORY_SIZE",
    "BATCH_SIZE",
    "TARGET_UPDATE_FREQ",
    "EPSILON_START",
    "EPSILON_END",
    "EPSILON_DECAY",
    "MAX_EPISODES",
    "EVAL_EPSILON",
    # Q-Learning config
    "ALPHA",
    "GAMMA",
    "EPSILON_START",
    "EPSILON_END",
    "EPSILON_DECAY",
    "Q_VALUE_TOLERANCE",
    "Q_TABLE_INIT_RANGE",
    "MAX_EPISODES",
    "EVAL_EPSILON",
    "GRID_SEARCH_N_EPISODES",
    "GRID_SEARCH_N_EVAL",
    "GRID_SEARCH_ALPHA",
    "GRID_SEARCH_GAMMA",
    "GRID_SEARCH_EPSILON_DECAY",
    "GRID_SEARCH_EVAL_EPSILON",
    "GRID_SEARCH_TOLERANCE",
    "GRID_SEARCH_EPSILON_START",
    "GRID_SEARCH_EPSILON_END",
    # Trainer config
    "N_EPISODES",
    "EVAL_EPSILON",
    "MAX_EVAL_STEPS",
    "PRINT_FREQUENCY",
    "SAVE_FREQUENCY",
    "EARLY_STOPPING_PATIENCE",
    "EARLY_STOPPING_MIN_DELTA",
    "N_EVAL_EPISODES",
    "SAVE_PATHS",
    "SAVE_METRICS",
    "SAVE_MODELS",
    "PATH_SAVE_FREQUENCY",
    "MAX_PATH_EPISODES",
    "METRICS_SAVE_FREQUENCY",
    "PLOT_FREQUENCY",
]
